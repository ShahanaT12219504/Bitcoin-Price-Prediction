# ğŸ“ˆ Bitcoin Price Prediction Using Machine Learning ğŸ§ ğŸ’°

## ğŸ“ Overview
This project uses machine learning to predict Bitcoin's closing price based on historical price data. The goal is to assist traders and investors with smarter decisions by forecasting short-term price trends using regression-based models.

## ğŸ¯ Objectives
- Predict Bitcoin closing prices using historical data.
- Apply feature engineering to improve model performance.
- Compare regression models like Linear Regression, SVR, and Random Forest.

## ğŸ“š Dataset
- **Source**: [GeeksforGeeks Bitcoin Dataset](https://media.geeksforgeeks.org/wp-content/uploads/20240917132611/bitcoin.csv)
- **Size**: 2713 rows Ã— 7 columns
- **Features**: `Date`, `Open`, `High`, `Low`, `Close`, `Adj Close`, `Volume`
- **Engineered Features**:
  - `open-close`: Daily price difference
  - `low-high`: Price range within the day
  - `year`, `month`, `day`: Extracted from `Date`
  - `is_quarter_end`: Boolean flag for quarter-end days

## ğŸ§¹ Data Preprocessing
- No missing values ğŸ‰
- Outliers handled using the IQR method, capped at the 99th percentile.
- Feature selection via:
  - Correlation Matrix
  - Recursive Feature Elimination (RFE)
  - Random Forest feature importance

## ğŸ› ï¸ Tools & Libraries
- Python ğŸ
- `pandas`, `numpy`, `matplotlib`, `seaborn`
- `scikit-learn` for modeling
- `RandomForestRegressor`, `SVR`, `LinearRegression`

## ğŸ¤– Machine Learning Models
1. **Linear Regression** â€“ For baseline performance
2. **Support Vector Regression (SVR)** â€“ Handles non-linearity
3. **Random Forest Regressor** â€“ Best performer with ensemble magic ğŸŒ²

## âš™ï¸ Model Training
- Dataset split: 80% train / 20% test
- Feature scaling and selection applied
- Hyperparameter tuning with `GridSearchCV`

## ğŸ“Š Evaluation Metrics
- **RMSE (Root Mean Squared Error)**
- **RÂ² Score**

| Model               | RMSE     | RÂ² Score |
|--------------------|----------|----------|
| Linear Regression  | 1034.21  | 0.72     |
| SVR                | 612.42   | 0.85     |
| ğŸ† Random Forest    | 456.80   | 0.91     |

## âœ… Results & Insights
- **Random Forest** outperformed all models with the lowest RMSE and highest RÂ².
- SVR showed good potential but required careful parameter tuning.
- Linear Regression was the weakest due to multicollinearity issues.

## ğŸ”® Future Work
- Add external factors like news sentiment and macroeconomic indicators ğŸ“ˆğŸ“°
- Try deep learning models like LSTM for time-series prediction ğŸ”ğŸ§ 
- Real-time prediction using API integration
